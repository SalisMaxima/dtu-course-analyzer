name: Update Course Data

on:
  workflow_dispatch: # Allows manual triggering from GitHub UI

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.3'  # Recommended: 3.12+, minimum: 3.10
          cache: 'pip'  # Built-in pip caching

      - name: Cache Playwright browsers
        uses: actions/cache@v3
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .  # Install package with CLI tools

      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: playwright install chromium

      - name: Authenticate and get cookie
        env:
          DTU_USERNAME: ${{ secrets.DTU_USERNAME }}
          DTU_PASSWORD: ${{ secrets.DTU_PASSWORD }}
        run: dtu-auth

      - name: Update Course Numbers
        run: dtu-get-courses

      - name: Run Scraper
        run: dtu-scrape

      - name: Validate Scraped Data
        run: dtu-validate data/coursedic.json

      - name: Analyze Data
        run: dtu-analyze extension

      - name: Commit and Push changes
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "Auto-update course data [skip ci]"
          file_pattern: "extension/db/data.js data/data.json data/coursedic.json data/coursenumbers.txt extension/db.html"
