name: Update Course Data

on:
  workflow_dispatch: # Allows manual triggering from GitHub UI

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.3'
          cache: 'pip'  # Built-in pip caching

      - name: Cache Playwright browsers
        uses: actions/cache@v3
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: playwright install chromium

      - name: Authenticate and get cookie
        env:
          DTU_USERNAME: ${{ secrets.DTU_USERNAME }}
          DTU_PASSWORD: ${{ secrets.DTU_PASSWORD }}
        run: python auth.py

      - name: Update Course Numbers
        run: python getCourseNumbers.py

      - name: Run Scraper
        run: python scraper_async.py

      - name: Validate Scraped Data
        run: python validator.py coursedic.json

      - name: Analyze Data
        # Generates the new data.js and data.json
        run: python analyzer.py extension

      - name: Commit and Push changes
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "Auto-update course data [skip ci]"
          # Add extension/db.html to this list:
          file_pattern: "extension/db/data.js data.json coursedic.json extension/db.html"
